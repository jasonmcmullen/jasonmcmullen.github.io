---
layout: post
title: "IaC into ProxMox: Automating my home host"
date: 2025-12-30
last_modified_at: 2025-12-30T12:00:00-05:00
categories:
  - Blog
  - Infrastructure
tags:
  - IaC
  - ProxMox
  - Terraform
  - Ansible
  - cloud-init
---

# IaC into ProxMox: Automating my home host

Over the last few months I moved my ProxMox host from mostly manual steps to an Infrastructure-as-Code driven workflow. The goal was simple: treat my home lab like a repeatable, auditable platform — define VMs and LXC containers, storage, and basic networking in code, and use configuration management to converge systems after build.

This post summarizes the approach, the tools I used, and the concrete commands I run when bringing up or changing a machine on my ProxMox host.

Note on sources: I cross-referenced the TechHut guide "Must Have Homelab Services" (https://techhut.tv/must-have-home-server-services-2025/) while researching services to mention below. All text in this post is written in my own words and organized around my personal Terraform + Ansible workflow; only service names are the same where necessary for clarity.

## Goals

- Reproducible VM/container definitions (capacity, disk, networks)
- Declarative immutability for images and cloud-init userdata
- Idempotent configuration with Ansible after provisioning
- Safe change workflow (plan → review → apply) with versioned code

## Tools and why

- `Terraform` (with the community ProxMox provider): author the VM/LXC definitions, disks, and network attachments. Terraform gives me a plan/apply workflow so I can review changes before making them.
- `cloud-init` + templates: for initial user creation, SSH keys, and networking on VMs. I build a small library of `cloud-init` user-data snippets to keep things consistent.
- `Ansible`: post-provisioning configuration (users, packages, services). Ansible runs against the ephemeral IP from cloud-init and converges the system to the expected state.
- `Packer` (optional): build golden images that are deployed by Terraform when useful.
- ProxMox ZFS storage: I keep data on ZFS datasets and use snapshots for quick rollbacks.

## Repository layout (what I track)

- `infrastructure/terraform/`: Terraform modules and environment code (VMs, networks, storage classes)
- `infrastructure/ansible/`: playbooks and roles for post-provisioning
- `infrastructure/cloud-init/`: reusable user-data templates

If you look in the repo you’ll find the top-level structure mirrors these conventions — keep VM definitions in `terraform/` and configuration in `ansible/`.

## Typical workflow and example commands

1. Edit the Terraform VM definition (e.g., give a new disk size or change cores).
2. Review planned changes:

```
cd infrastructure/terraform
terraform init
terraform plan -out=tfplan
terraform show -no-color tfplan
```

3. Apply after review:

```
terraform apply tfplan
```

4. Once the VM comes up (cloud-init sets SSH keys), run Ansible to configure it:

```
cd infrastructure/ansible
ansible-playbook -i inventory/hosts site.yml --limit new-host
```

Notes:
- I keep the ProxMox API token in my CI secrets or a local encrypted file — avoid embedding it in source. The Terraform provider accepts `proxmox_api_token_id` and `proxmox_api_token_secret` (or a `PROXMOX_*` env var).
- For cloud-init based VMs I use a small `userdata` template that installs the SSH key and sets the hostname; that template lives in `infrastructure/cloud-init/`.

## Reproduce this tutorial

The step-by-step Quickstart walkthrough has been merged into the operational rollout document. To follow the exact commands and scripts used in this post, see [infrastructure/IaC-rollout.md](infrastructure/IaC-rollout.md).

## Patterns that worked well

- Keep small, focused Terraform modules: one for `vm`, one for `lxc`, one for `network` attachments. That makes it easy to reuse and test.
- Use Ansible tags for phased runs (e.g., `--tags base,monitoring`) so I can run only the relevant portion after an update.
- Rely on ZFS snapshots before doing risky changes: snapshots + Terraform/disk changes are a safe combo for home lab experimentation.

## Common pitfalls & tips

- ProxMox networking can be confusing: I standardize on bridged networking and attach VLANs in Terraform when needed.
- Validate `cloud-init` userdata locally (e.g., using `cloud-init devel schema --auto`) before pushing templates.
- When changing disks or VM types, always `plan` first — Terraform will show disruptive operations (destroy/create) clearly.

## Where I go next

- Expand CI checks to validate Terraform formatting and Terraform plan diffs on PRs.
- Add `Packer` pipeline to produce more robust golden images that reduce post-provisioning time.

If you want, I can add concrete snippets from my `terraform/` and `ansible/` folders (provider configuration, a sample VM module, and a `cloud-init` userdata template) into this post — tell me which piece you'd like shown.


## Services I run (and how I provision them)

Following the TechHut "Must Have Homelab Services" guidance, here are the common services I run and how they map to my IaC workflow. This keeps the platform repeatable and makes upgrades/test changes low-risk.

- Reverse proxy & TLS — `NGINX Proxy Manager` or `SWAG`: provision as an LXC/container via Terraform (creates dataset + container), deploy the proxy stack with Ansible or a `docker-compose` role, and manage certs via Let’s Encrypt automatically.

- DNS & remote access — `Pi-hole` / `AdGuard Home`, `Cloudflare DDNS`, `Twingate` or `Tailscale`: create a small networking LXC with Terraform, inject secrets via CI or Ansible vault, and bootstrap runtime config with Ansible tasks.

- Media stack — `Plex` / `Jellyfin`, `Tautulli`, `Overseerr`, `Radarr`, `Sonarr`, `Prowlarr`, `qBittorrent`: deploy as container stacks; Terraform provisions the VM/LXC and ZFS datasets for media, Ansible applies the compose files and user/group permissions.

- Files & photos — `Nextcloud`, `Immich`, `File Browser`: each gets persistent ZFS datasets created by Terraform; cloud-init + Ansible handle initial users and TLS exposure via the reverse proxy.

- Passwords & secrets — `Vaultwarden`: run as a single container with a mounted dataset; secrets (admin tokens, DB passwords) live in CI secrets or an encrypted vault and are injected at deploy time.

- Smart home & NVR — `Home Assistant`, `Frigate`, `Zigbee2MQTT`: provision VMs or privileged LXCs (for USB passthrough) via Terraform; Ansible ensures drivers, runtime users, and service units are configured.

- Monitoring & metrics — `Prometheus` + `Node Exporter`, `InfluxDB`, `Grafana`: create a monitoring VM with Terraform; Ansible installs exporters and bootstraps dashboards (I keep Grafana dashboards as JSON in `infrastructure/monitoring/` and import them from Ansible).

- Utilities & management — `Portainer`, `Cockpit`, `File Browser`: small utility containers/LXCs managed by the same Terraform→Ansible lifecycle so I can rebuild easily.

- Backups & snapshots — ZFS snapshots plus `restic` for offsite backups: Terraform creates datasets and snapshot policies; Ansible installs restic and scheduled jobs that send encrypted backups to an offsite target.

Practical IaC patterns I use for these services:

- Use Terraform modules to create a VM/LXC + ZFS dataset pair so an app always has predictable storage.
- Store compose files and app-specific configs in `infrastructure/apps/<app>/` and have Ansible deploy them idempotently.
- Keep sensitive data out of source — use CI secrets, `ansible-vault`, or environment variables consumed at runtime.
- Automate pre-change safety: snapshot the VM/dataset with ZFS before any Terraform apply that will change disks or destroy resources.

If you'd like, I can add a concrete example for one service (e.g., a Terraform LXC module plus Ansible role for `vaultwarden` or a `docker-compose` snippet for the media stack). Which example should I add into the post?
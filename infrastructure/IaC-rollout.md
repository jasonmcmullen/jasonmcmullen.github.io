# IaC Rollout: ProxMox host

This document captures the step-by-step Infrastructure-as-Code rollout I used to provision the services described in my post and the TechHut reference. It records commands, structure, and safety steps so future changes are auditable.

Summary
- Goal: Provision ProxMox VMs/LXCs, storage, and apps (media, DNS, proxies, backups, monitoring) via Terraform + cloud-init and configure them with Ansible.
- Safety model: plan → snapshot → apply → converge → test.

Quickstart: Deploy Nginx Proxy Manager (minimal)

This minimal walkthrough shows the simplest path from code → running service. It assumes you have a ProxMox API token available and a Debian LXC template on your node. Files used in this example:

- `infrastructure/terraform/envs/example/main.tf` (example root)
- `infrastructure/terraform/modules/lxc` (module scaffold)
- `infrastructure/ansible/roles/nginx-proxy-manager` (role + templates)
- `infrastructure/apps/nginx-proxy-manager/docker-compose.yml` (compose file)

1) Export ProxMox credentials locally (PowerShell example):

```powershell
$env:PROXMOX_HOST = "proxmox.example.local"
$env:PROXMOX_API_TOKEN_ID = "user@pam!tokenid"
$env:PROXMOX_API_TOKEN_SECRET = "<secret>"
```

2) Initialize Terraform and review plan:

```bash
cd infrastructure/terraform/envs/example
terraform init
terraform plan -out=tfplan
terraform show -no-color tfplan
```

3) Snapshot critical datasets (safety):

```bash
# run on ProxMox host or via SSH
sudo zfs snapshot rpool/data/nginx-proxy-manager@pre-deploy-$(date +%Y%m%d-%H%M)
```

4) Apply Terraform to create LXC (after review):

```bash
terraform apply tfplan
```

5) Auto-generate Ansible inventory (or manually create it):

```bash
cd infrastructure/terraform/envs/example
./generate_inventory.sh
# or on Windows PowerShell
.\generate_inventory.ps1
```

6) Run Ansible to install Docker (via `common` role) and deploy `nginx-proxy-manager` role:

```bash
cd infrastructure/ansible
ansible-playbook -i inventory/hosts site.yml --limit nginx-proxy -e "roles_to_run='common,nginx-proxy-manager'"
```

7) Visit the host IP on ports 81 (admin) and 80/443 for proxied services. If using external DNS, create DNS records and configure the proxy via the NPM UI.

Notes: Replace IPs, dataset names, and secrets with values that match your environment.

Cross-links
- Blog post describing the design and high-level rationale: [IaC into ProxMox: Automating my home host](_posts/2025-12-30-IaC.md)

Prerequisites
- Local workstation with: `terraform` (v1.4+ recommended), `ansible` (2.10+), `ssh`, `jq`, `restic` (optional), `packer` (optional).
- A ProxMox server with API access: API token with appropriate permissions.
- ZFS available on ProxMox node for datasets and snapshots.

Repository layout (recommended)
- `infrastructure/terraform/` — provider config, modules, environments
  - `modules/vm/` — module that creates a VM or LXC and optional ZFS dataset
  - `envs/production/` — terraform root with `main.tf`, `variables.tf`, `backend.tf`
- `infrastructure/ansible/` — playbooks, roles, inventories
  - `roles/common/`, `roles/<app>/`
  - `inventory/hosts` (generated by terraform outputs or static for testing)
- `infrastructure/cloud-init/` — reusable cloud-init userdata templates
- `infrastructure/apps/<app>/` — docker-compose files, configs, templates

Provider & secrets
- Do NOT commit credentials. Use one of:
  - CI secret store for automated pipelines.
  - Local `.env` read by `direnv` or shell export for manual runs.
  - `ansible-vault` for secrets consumed by Ansible.

Terraform provider example (high-level)
- Provider accepts either token or username/password. Export env vars before running:

```powershell
$env:PROXMOX_HOST = "proxmox.example.local"
$env:PROXMOX_API_TOKEN_ID = "user@pam!tokenid"
$env:PROXMOX_API_TOKEN_SECRET = "<secret>"
```

- Typical workflow (manual):

```bash
cd infrastructure/terraform/envs/production
terraform init
terraform validate
terraform plan -out=tfplan
terraform show -no-color tfplan
# snapshot before apply (see ZFS snapshots below)
terraform apply tfplan
```

Module pattern (recommended)
- `modules/vm` interface examples:
  - inputs: `name`, `cores`, `memory`, `disk_gb`, `storage_pool`, `cloud_init_userdata`, `network_bridge`, `zfs_dataset_name`
  - outputs: `vm_id`, `vm_ip`, `ssh_user`
- Encapsulate ZFS dataset creation + dataset ACLs in a helper module used by the VM module.

cloud-init templates
- Keep small parameterized templates in `infrastructure/cloud-init/`.
- Example variables to inject from Terraform: `ssh_authorized_keys`, `hostname`, `users`.

Example cloud-init snippet (high-level)

```yaml
#cloud-config
hostname: ${hostname}
users:
  - name: infrauser
    ssh-authorized-keys:
      - ${ssh_key}
    sudo: ALL=(ALL) NOPASSWD:ALL
packages:
  - apt-transport-https
  - ca-certificates
runcmd:
  - [ cloud-init-per, once, setup, /usr/local/bin/setup-script.sh ]
```

Ansible structure & run
- `site.yml` orchestrates roles: `common`, `monitoring`, `apps:<app>`.
- Use `inventory/hosts` created from Terraform outputs (terraform can write a small `hosts` file with `local_file` or you can use `terraform-inventory`).

Ansible run example:

```bash
cd infrastructure/ansible
ansible-playbook -i inventory/hosts site.yml --limit proxmox-new-vm
```

ZFS snapshots & pre-change safety
- Before any Terraform apply that may change disks or destroy resources, take a snapshot:

```bash
# on ProxMox host (adjust dataset path)
sudo zfs snapshot rpool/data/media@pre-terraform-$(date +%Y%m%d-%H%M)
```

- For scripted snapshots from CI/automation, use SSH to call the dataset snapshot API or CLI.

Example app lifecycle (vaultwarden as exemplar)
1. Terraform: create LXC `vaultwarden` with a ZFS dataset `rpool/vaultwarden` and cloud-init that writes basic config.
2. Terraform outputs `vaultwarden_ip` and `ssh_user`.
3. Ansible: run role `vaultwarden` to deploy `docker-compose.yml`, create env file from CI secrets, and ensure `systemd` service or container manager is running.

Auto-generating Ansible inventory from Terraform outputs
-----------------------------------------------

To avoid editing inventory by hand, use the helper script included in `infrastructure/terraform/envs/example/`:

- `generate_inventory.sh` (bash)
- `generate_inventory.ps1` (PowerShell for Windows)

Usage (bash):

```bash
cd infrastructure/terraform/envs/example
terraform output -json >/dev/null || echo "Run 'terraform apply' first"
./generate_inventory.sh
# then run ansible
cd ../../ansible
ansible-playbook -i inventory/hosts site.yml --limit nginx-proxy
```

Usage (PowerShell):

```powershell
Set-Location infrastructure/terraform/envs/example
terraform output -json | Out-Null # ensures outputs exist
.\generate_inventory.ps1
Set-Location ..\..\ansible
ansible-playbook -i inventory/hosts site.yml --limit nginx-proxy
```

What the script does:
- Reads `terraform output -json` and looks for an output named `npm_ip` or any output ending with `_ip`/`ip`.
- Writes a minimal Ansible inventory at `infrastructure/ansible/inventory/hosts` with the discovered IP and the `infrauser` SSH user.

If your Terraform module uses a different output name, either add an explicit `output "npm_ip" { value = <resource_ip> }` to the terraform root or modify the script to look for your output name.

Docker-compose snippet (example stored at `infrastructure/apps/vaultwarden/docker-compose.yml`):

```yaml
version: '3.8'
services:
  vaultwarden:
    image: vaultwarden/server:latest
    restart: unless-stopped
    volumes:
      - /srv/vaultwarden/data:/data
    environment:
      DATABASE_URL: sqlite:/data/db.sqlite
      ADMIN_TOKEN: ${VAULTWARDEN_ADMIN_TOKEN}
    ports:
      - "8081:80"
```

CI pipeline recommendations (plan/review/apply)
- Stage 1: `terraform fmt`/`validate` on PR.
- Stage 2: `terraform plan` and save plan artifact; publish human-readable `terraform show` output as a comment on PR.
- Stage 3: Merge triggers a protected `apply` job run from CI with access to ProxMox secrets.
- Keep `apply` gated and logged.

Secrets handling
- Use the CI secrets store for `PROXMOX_API_TOKEN_SECRET`, DB passwords, and app admin tokens.
- Prefer `ansible-vault` for long-lived secrets in repo when necessary, but store the vault password outside the repo.

Testing & verification
- After apply and Ansible converge, run smoke tests:
  - SSH connects as expected.
  - Services respond on expected ports (curl to endpoints behind proxy).
  - Grafana dashboards import successfully (if applicable).

Rollback plan
- If change is disruptive, steps:
  1. `terraform destroy` only if intended; otherwise revert code and plan/apply to return to previous state.
  2. Restore ZFS snapshot to dataset:

```bash
sudo zfs rollback rpool/data/media@pre-terraform-20251230-1200
```

  3. Re-run Ansible to fix configuration drift.

History & changelog
- Keep a `infrastructure/CHANGELOG.md` or use git history for rollbacks and audit.

List of services & provisioning pattern (short mapping)
- Reverse proxy: LXC/container + compose; TLS via Let’s Encrypt; managed by Ansible.
- DNS/remote access: small privileged LXC; secrets via CI; Ansible bootstraps blocklists/keys.
- Media services: VMs/LXCs with ZFS storage; containers for apps; Ansible manages permissions + compose.
- Monitoring: dedicated VM; Ansible installs Prometheus + node_exporter, Grafana imports dashboards from `infrastructure/monitoring/`.
- Backups: restic jobs scheduled by Ansible; snapshots pre-change.

Detailed backup, snapshot & rollback procedures
-----------------------------------------------

This section documents exact commands, naming conventions, and practical tips I use to protect data and recover from disruptive changes.

1) Principles
- Always snapshot before any disruptive change (disk resize, destroy/create, migration).
- Keep both on-host filesystem snapshots (ZFS) for fast rollback and off-host backups (restic) for disaster recovery.
- Quiesce stateful services before snapshot when possible (databases, exchange cursors). When not possible, perform DB dumps and back those up.

2) ZFS snapshots (fast local rollback)

- Create a snapshot (recursive if you want child datasets):

```bash
# single dataset
sudo zfs snapshot rpool/data/nginx-proxy-manager@pre-terraform-20251230-1200

# recursive for dataset and children
sudo zfs snapshot -r rpool/data@pre-terraform-20251230-1200
```

- List snapshots:

```bash
sudo zfs list -t snapshot -o name,used,refer -r rpool/data
```

- Rollback to a snapshot (destructive to current data):

```bash
# WARNING: rollback replaces current dataset state with the snapshot state
sudo zfs rollback rpool/data/nginx-proxy-manager@pre-terraform-20251230-1200
```

- Clone a snapshot (safe testing):

```bash
sudo zfs clone rpool/data/nginx-proxy-manager@pre-terraform-20251230-1200 rpool/test/nginx-proxy-manager-clone
# export or mount the clone on a test VM to validate
```

- Send/receive snapshots to a remote ZFS target (incremental after initial send):

```bash
# initial send
sudo zfs send -R rpool/data/nginx-proxy-manager@initial | ssh backup.example.com sudo zfs receive backup/data/nginx-proxy-manager

# incremental (from previous snapshot tag)
sudo zfs send -R rpool/data/nginx-proxy-manager@pre-terraform-20251230-1200 ^rpool/data/nginx-proxy-manager@previous-snap | ssh backup.example.com sudo zfs receive backup/data/nginx-proxy-manager
```

3) Restic for offsite, encrypted backups

- Initialize repo (on backup host or S3-compatible remote):

```bash
export RESTIC_REPOSITORY=s3:s3.amazonaws.com/bucketname/path
export RESTIC_PASSWORD="<strong-password-from-secrets>"
restic init
```

- Example backup command (backup dataset mountpoints or application dumps):

```bash
# backup container data dir and other paths
restic backup /srv/nginx-proxy-manager/data --tag nginx-proxy-manager
```

- Restore latest snapshot to a target path:

```bash
restic restore latest --target /tmp/restore-test
```

- Automation notes:
  - Keep `RESTIC_PASSWORD` in CI/secret manager; use short-lived credentials for cloud backends.
  - Use `restic check` periodically to verify repository integrity.

4) Database backups (MySQL/MariaDB example for NPM)

- Example mysqldump (run from host or container):

```bash
mysqldump -u root -p --databases nginxproxymanager > /tmp/nginxproxymanager.sql
restic backup /tmp/nginxproxymanager.sql --tag db-dump
rm /tmp/nginxproxymanager.sql
```

- For larger DBs use logical backups with compression or physical backups with `xtrabackup`.

5) Snapshot before Terraform apply (workflow)

```bash
# 1. Plan
cd infrastructure/terraform/envs/production
terraform init
terraform plan -out=tfplan

# 2. Create snapshots for affected datasets (example assumes you know datasets)
ssh proxmox sudo zfs snapshot -r rpool/data@pre-terraform-$(date +%Y%m%d-%H%M)

# 3. Apply
terraform apply tfplan

# 4. Run Ansible to converge
cd ../../ansible
ansible-playbook -i inventory/hosts site.yml --limit <target-host>

# 5. Verify, then delete old snapshots according to retention policy
```

6) Automated snapshot script (example)

Create `/usr/local/bin/proxmox_pre_terraform_snapshot.sh` on a management host (or run via CI):

```bash
#!/usr/bin/env bash
set -euo pipefail
STAMP=$(date +%Y%m%d-%H%M)
DS_LIST=(rpool/data rpool/apps rpool/media)
for ds in "${DS_LIST[@]}"; do
  ssh proxmox sudo zfs snapshot -r ${ds}@pre-terraform-$STAMP
done
echo "Created snapshots with tag pre-terraform-$STAMP"
```

7) Restore/rollback example (fast local rollback)

Case A: Temporary test restore via clone

```bash
sudo zfs clone rpool/data/nginx-proxy-manager@pre-terraform-20251230-1200 rpool/test/npm-rollback
# mount/verify test files and services
```

Case B: Full rollback

```bash
# Stop services touching dataset, then rollback
ssh proxmox sudo systemctl stop lxc@<vmid>.service # or stop container
ssh proxmox sudo zfs rollback rpool/data/nginx-proxy-manager@pre-terraform-20251230-1200
ssh proxmox sudo systemctl start lxc@<vmid>.service
```

8) Regular retention & housekeeping
- Keep a retention policy: e.g., hourly snapshots for 24 hours, daily for 14 days, weekly for 12 weeks. Implement via cron or zfs-auto-snapshot or a small script pushed by Ansible.
- Use `zfs destroy` to prune old snapshots:

```bash
sudo zfs destroy rpool/data/nginx-proxy-manager@old-snap
```

9) Test restores regularly
- Periodically perform a test restore to a non-production clone and run smoke tests. Store test results in CI or a log for audit.

Security notes
- Never store unencrypted backups in public places. Use restic with encryption and strong passwords stored in a secret manager.
- Limit SSH keys that can execute snapshot/send commands; use a dedicated backup user.

If you want, I can:
- Add an Ansible role `roles/backup` that deploys snapshot scripts, configures `restic` with systemd timers, and enforces retention, or
- Create a CI job that runs pre-apply snapshot commands remotely before allowing a protected `apply` job.

Editing blog posts (keep published date)
--------------------------------------

When editing or adding files under `_posts/`, preserve a clear human-readable publication line at the end of the post in the format:

Published on YYYY-MM-DD.

This should match the `date:` value in the post's front matter. Keeping this line makes historical edits and site generation audits easier for readers and maintainers.


Next steps (suggested)
1. Add `modules/vm` and `modules/zfs` in `infrastructure/terraform/modules/` (I can scaffold these).
2. Add an example `roles/vaultwarden` and `apps/vaultwarden/docker-compose.yml` and test locally against a non-production ProxMox test node.
3. Add CI pipeline to run `terraform plan` on PRs and require manual approval for `apply`.

Change record
- 2025-12-30: Initial rollout doc added.

---
If you want, I will now:
- scaffold `infrastructure/terraform/modules/vm` and a small `envs/production/main.tf` (safe minimal example), and
- scaffold `infrastructure/ansible/roles/vaultwarden` and `infrastructure/apps/vaultwarden/docker-compose.yml` as a working example.

Which example would you like me to create next? (suggestion: `vaultwarden` or `nginx-proxy-manager`)
